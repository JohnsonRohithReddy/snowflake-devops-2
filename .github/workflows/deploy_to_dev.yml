name: snowflake-devops-demo

on:
  push:
    branches:
      - dev
    paths:
      - '*/migrations/**'  # Watch all migration folders
  workflow_dispatch:

jobs:
  deploy-layer-changes:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Use Python 3.8.x
        uses: actions/setup-python@v2.2.1
        with:
          python-version: 3.8.x

      - name: Install dependencies
        run: |
          pip install pyyaml schemachange  # No need for yq now

      - name: Deploy layer changes
        env:
          SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
          SF_USERNAME: ${{ secrets.SF_USERNAME }}
          SF_ROLE: ${{ secrets.SF_ROLE }}
          SF_WAREHOUSE: ${{ secrets.SF_WAREHOUSE }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SF_PASSWORD }}
        run: |
          echo "GITHUB_WORKSPACE: $GITHUB_WORKSPACE"
          # Get schemas using Python script from config folder
          echo "Checking for schemas.yml in $GITHUB_WORKSPACE/config/schemas.yml"
          ordered_layers=$(python $GITHUB_WORKSPACE/config/get_schemas.py)
          if [ $? -ne 0 ]; then
            echo "Error: Failed to extract schemas, exiting"
            exit 1
          fi
          # Split the space-separated output into an array
          mapfile -t ordered_layers_array < <(echo "$ordered_layers")
          if [ ${#ordered_layers_array[@]} -eq 0 ]; then
            echo "Error: No schemas extracted, exiting"
            exit 1
          fi
          echo "Schemas extracted from schemas.yml: ${ordered_layers_array[@]}"
          # Detect available layers
          mapfile -t layers < <(find "$GITHUB_WORKSPACE" -maxdepth 1 -type d ! -name ".*" -exec sh -c 'test -d "{}/migrations" && echo {}' \; | sed 's|.*/||')
          if [ ${#layers[@]} -eq 0 ]; then
            echo "Error: No migration folders found, skipping deployment"
            exit 0
          fi
          echo "Detected layers: $(echo "${layers[@]}" | tr ' ' ' ')"
          echo "Processing layers in order: ${ordered_layers_array[@]}"
          # Initialize or load execution history
          history_file="$GITHUB_WORKSPACE/execution_history.yml"
          if [ -f "$history_file" ]; then
            latest_version=$(yq eval '.latest_version' "$history_file" || echo "0.0.0")
          else
            latest_version="0.0.0"
            echo "latest_version: $latest_version" > "$history_file"
            echo "executions: []" >> "$history_file"
          fi
          for layer in "${ordered_layers_array[@]}"; do
            if [[ " ${layers[*]} " =~ " ${layer} " ]]; then
              echo "Step 1: Processing $layer layer"
              var_file="$GITHUB_WORKSPACE/$layer/migrations/${layer}-var.yml"
              if [ -f "$var_file" ] && [ -r "$var_file" ]; then
                echo "Parsing variables from $var_file"
                vars=$(python $GITHUB_WORKSPACE/parse_vars.py "$var_file" 2> debug_$layer.log)
                echo "Parsed vars: $vars"
                if [ -z "$vars" ] || ! echo "$vars" | python -c "import json; json.loads(input())" 2>/dev/null; then
                  echo "Error: Invalid or empty vars JSON: $vars"
                  cat debug_$layer.log
                  vars='{"sf_database": "SF_DEVOPS_DEV_DB", "sf_schema": "'$layer'", "new_var": "'$layer'_value"}'
                fi
                database_name=$(echo "$vars" | python -c "import json, sys; print(json.loads(sys.stdin.read())['sf_database'])")
                schema_name=$(echo "$vars" | python -c "import json, sys; print(json.loads(sys.stdin.read())['sf_schema'])")
                echo "Extracted database_name: $database_name"
                echo "Extracted schema_name: $schema_name"
                echo "Step 2: Running schemachange for $layer with vars: $vars"
                ls -la "$GITHUB_WORKSPACE/$layer/migrations/scripts"  # List flat scripts
                schemachange_output=$(schemachange \
                  -f "$GITHUB_WORKSPACE/$layer/migrations/scripts" \
                  -a "$SF_ACCOUNT" \
                  -u "$SF_USERNAME" \
                  -r "$SF_ROLE" \
                  -w "$SF_WAREHOUSE" \
                  -d "$database_name" \
                  -c "$database_name.SCHEMACHANGE.CHANGE_HISTORY" \
                  --create-change-history-table \
                  --config-folder "$GITHUB_WORKSPACE/$layer/migrations/config" \
                  --vars "$vars" 2>&1)
                echo "$schemachange_output"
                # Check if scripts were applied
                if echo "$schemachange_output" | grep -q "scripts_applied=[1-9]"; then
                  # Extract applied scripts and commit message
                  applied_scripts=$(echo "$schemachange_output" | grep -o "Applying change script.*" | sed 's/.*a_script_name=//; s/ script_version=/ /')
                  commit_msg=$(git log -1 --pretty=format:%s)
                  # Increment version (simple increment for now)
                  new_version=$(echo "$latest_version" | awk -F. '{$NF++; print $1"."$2"."$NF}')
                  # Update history file
                  yq eval ".latest_version = \"$new_version\"" -i "$history_file"
                  yq eval ".executions += [{\"version\": \"$new_version\", \"layer\": \"$layer\", \"scripts\": [\"$applied_scripts\"], \"commit_msg\": \"$commit_msg\", \"timestamp\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"}]" -i "$history_file"
                  echo "Updated execution history with version $new_version"
                  latest_version=$new_version
                fi
              else
                echo "Error: $var_file not found or not readable, skipping $layer"
              fi
            else
              echo "Warning: Layer $layer not found, skipping"
            fi
          done

      - name: Cleanup
        if: always()
        run: |
          mapfile -t layers < <(find "$GITHUB_WORKSPACE" -maxdepth 1 -type d ! -name ".*" -exec sh -c 'test -d "{}/migrations" && echo {}' \; | sed 's|.*/||')
          for layer in "${layers[@]}"; do
            rm -rf "$GITHUB_WORKSPACE/$layer/migrations/scripts_temp"  # Cleanup any leftover temp dirs
          done
